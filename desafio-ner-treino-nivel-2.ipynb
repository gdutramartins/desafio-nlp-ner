{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thrown-classification",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import string\n",
    "import json\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from tqdm import tqdm\n",
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training import Example\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "civil-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_DRUG_PROTEIN = 'DRUG-PROTEIN'\n",
    "LABEL_CHEMICAL = 'CHEMICAL'\n",
    "LABEL_DISEASE = 'DISEASE'\n",
    "LABEL_SPECIES = 'SPECIES'\n",
    "\n",
    "LABEL_LIST = [LABEL_DRUG_PROTEIN,\n",
    "              LABEL_CHEMICAL,\n",
    "              LABEL_DISEASE,    \n",
    "              LABEL_SPECIES]\n",
    "\n",
    "LABEL_TO_DIR = {\n",
    "    LABEL_DRUG_PROTEIN: ['BC2GM', 'JNLPBA'],\n",
    "    LABEL_CHEMICAL: ['BC4CHEMD','BC5CDR-chem'],\n",
    "    LABEL_DISEASE: ['BC5CDR-disease', 'NCBI-disease'],    \n",
    "    LABEL_SPECIES: ['linnaeus', 's800']\n",
    "}\n",
    "\n",
    "DATA_ORIGIN_PATH = os.path.join(\"data\",\"origin\")\n",
    "DATA_PREPARED_PATH = os.path.join(\"data\", \"prepared\")\n",
    "DATA_AGGREGATE_PATH = os.path.join(DATA_PREPARED_PATH, \"aggregate\")\n",
    "\n",
    "WORD_VECTOR_PATH = \"word_vec\"\n",
    "WORD_VECTOR_MODEL_NAME = os.path.join(WORD_VECTOR_PATH, \"biomed.model\")\n",
    "WORD_VECTOR_FILE_NAME = os.path.join(WORD_VECTOR_PATH, \"biomed_word2vec.txt\")\n",
    "WORD_VECTOR_EXPORT_TENSORBOARD_PATH = os.path.join(WORD_VECTOR_PATH, \"tensorboard\", \"biomed_ner\")\n",
    "\n",
    "MODEL_PATH = \"model\"\n",
    "MODEL_TRAIN_PATH = os.path.join(MODEL_PATH, \"train\")\n",
    "MODEL_ACTUAL_PATH = os.path.join(MODEL_PATH, \"actual\")\n",
    "\n",
    "TSV_EXTENSION = \".tsv\"\n",
    "JSON_EXTENSION = \".json\"\n",
    "SPACY_EXTENSION = \".spacy\"\n",
    "\n",
    "TRAIN_DEV_DATASET = \"train_dev\"\n",
    "TRAIN_DATASET = \"train\"\n",
    "VALIDATE_DATASET = \"devel\"\n",
    "TEST_DATASET = \"test\"\n",
    "\n",
    "DATASET_TYPE = [TRAIN_DATASET, VALIDATE_DATASET, TEST_DATASET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "identical-optimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(label, dataset_type, group_by_label=True):\n",
    "    data = []\n",
    "    if group_by_label:\n",
    "        file = os.path.join(DATA_PREPARED_PATH, label, label + \"-\" + dataset_type + JSON_EXTENSION)\n",
    "    else:\n",
    "        file = os.path.join(DATA_AGGREGATE_PATH, dataset_type + JSON_EXTENSION)\n",
    "        \n",
    "    with open (file, \"r\", encoding=\"utf-8\") as f:\n",
    "        json_data = json.load(f)\n",
    "    for an in json_data:\n",
    "        texto = an[\"texto\"]\n",
    "        entities = []\n",
    "        for entidade in an[\"entities\"]:\n",
    "            info = (entidade[\"start\"], entidade[\"end\"], entidade[\"label\"])\n",
    "            entities.append(info)\n",
    "        data.append((texto,{\"entities\":entities}))\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "arctic-bundle",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_data_for_evaluation(data, nlp_model): \n",
    "    data_formated = []\n",
    "    for text, annotations in data:\n",
    "        doc = nlp_model.make_doc(text)\n",
    "        example = Example.from_dict(doc, annotations)\n",
    "        data_formated.append(example)\n",
    "    return data_formated\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organic-sapphire",
   "metadata": {},
   "source": [
    "### Treinando multiple labels com multiplas camadas de NER Pré-Treinadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "disturbed-corner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_spacy_multiple_label_multiple_ner(train_data, validate_data, iterations, lista_model_label, description):\n",
    "    nlp_train = spacy.blank(\"en\")\n",
    "    lista_ner = []\n",
    "    \n",
    "    for sm in lista_model_label:\n",
    "        nlp_train.add_pipe(sm[\"label\"] + \"_ner\", source=sm[\"model\"])\n",
    "        lista_ner.append(sm[\"label\"] + \"_ner\")\n",
    "    \n",
    "    best_ents_p = -1\n",
    "    best_ents_r = -1\n",
    "    best_ents_f = -1\n",
    "    \n",
    "    with open(os.path.join(MODEL_TRAIN_AGGRATE_PATH, \"log_treino.txt\" ) , \"a\") as log_file:\n",
    "        log_file.write(\"\\n\")\n",
    "        log_file.write(f\"=======> [TREINO AGREGADO] Inicio Treino {time.strftime('%d/%m/%Y %H:%M:%S', time.gmtime(time.time()))} ===================================== \\n\")\n",
    "        log_file.write(f\"Detalhes: {description} \\n\\n\")\n",
    "        \n",
    "        other_pipes = [pipe for pipe in nlp_train.pipe_names if pipe not in lista_ner]\n",
    "        with nlp_train.disable_pipes(*other_pipes):\n",
    "            optimizer = nlp_train.begin_training()\n",
    "            print(f\"{'#IT':5} | {'Loss':8} | {'Prec':6} | {'Recall':6} | {'F_Scr':6} | {'Save Mod':8} | {'Duração':10} \")\n",
    "            log_file.write(f\"{'#IT':5} | {'Loss':8} | {'Prec':6} | {'Recall':6} | {'F_Scr':6} | {'Save Mod':8} | {'Duracao':10} \\n\")\n",
    "            \n",
    "            for itn in range(iterations):\n",
    "                start_time = time.time()\n",
    "                linha = f\"{str(itn):5} | \"\n",
    "                random.shuffle(train_data)\n",
    "                losses = {}\n",
    "                batches = minibatch(train_data, size=512)\n",
    "\n",
    "                for batch in batches:\n",
    "                    for text, annotations in batch:\n",
    "                        doc = nlp_train.make_doc(text)\n",
    "                        example = Example.from_dict(doc, annotations)\n",
    "                        nlp_train.update( [example],\n",
    "                            drop=0.2,  \n",
    "                            sgd=optimizer,\n",
    "                            losses=losses)\n",
    "\n",
    "                validate_metrics = nlp_train.evaluate(format_data_for_evaluation(validate_data, nlp_train))\n",
    "                linha += f\"{losses[list(losses)[0]]:08.2f} | {validate_metrics['ents_p']*100:06.2f} | {validate_metrics['ents_r']*100:06.2f} | {validate_metrics['ents_f']*100:06.2f} | \"\n",
    "\n",
    "                if (validate_metrics[\"ents_f\"] > best_ents_f):\n",
    "                    best_ents_r = validate_metrics[\"ents_r\"]\n",
    "                    best_ents_f = validate_metrics[\"ents_f\"]\n",
    "                    best_ents_p = validate_metrics[\"ents_p\"]\n",
    "                    linha += f\"{'S':8} | \"\n",
    "                    \n",
    "                    Path(MODEL_TRAIN_AGGRATE_PATH).mkdir(parents=True, exist_ok=True)\n",
    "                    nlp_train.to_disk(path)                \n",
    "                else:\n",
    "                    linha += f\"{'N':8} | \"\n",
    "\n",
    "                elapsed = time.strftime(\"%H:%M:%S\", time.gmtime(time.time() - start_time))\n",
    "                linha += elapsed\n",
    "\n",
    "                print(linha)\n",
    "                print(validate_metrics)\n",
    "                log_file.write(linha + \"\\n\")\n",
    "                log_file.flush()\n",
    "    return nlp_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "civil-vinyl",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_model_label = []\n",
    "\n",
    "path = os.path.join(MODEL_ACTUAL_PATH, LABEL_SPECIES)\n",
    "nlp_species = spacy.load(path)\n",
    "lista_model_label.append({\"label\": LABEL_SPECIES, \"model\": nlp_species})\n",
    "\n",
    "path = os.path.join(MODEL_ACTUAL_PATH, LABEL_DRUG_PROTEIN)\n",
    "nlp_drug_protein = spacy.load(path)\n",
    "lista_model_label.append({\"label\": LABEL_DRUG_PROTEIN, \"model\": nlp_drug_protein})\n",
    "\n",
    "path = os.path.join(MODEL_ACTUAL_PATH, LABEL_CHEMICAL)\n",
    "nlp_chemical = spacy.load(path)\n",
    "lista_model_label.append({\"label\": LABEL_CHEMICAL, \"model\": nlp_chemical})\n",
    "\n",
    "path = os.path.join(MODEL_ACTUAL_PATH, LABEL_DISEASE)\n",
    "nlp_disease = spacy.load(path)\n",
    "lista_model_label.append({\"label\": LABEL_DISEASE, \"model\": nlp_disease})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "assumed-somerset",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#IT   | Loss     | Prec   | Recall | F_Scr  | Save Mod | Duração    \n",
      "0     | 129170.33 | 048.57 | 062.19 | 054.54 | S        | 02:17:54\n",
      "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.48572913572913573, 'ents_r': 0.6218795748806967, 'ents_f': 0.5454363540858951, 'ents_per_type': {'DRUG-PROTEIN': {'p': 0.3947340482004459, 'r': 0.639051220350636, 'f': 0.48802257662269477}, 'CHEMICAL': {'p': 0.5895818913584044, 'r': 0.6602646915281486, 'f': 0.6229246228433682}, 'SPECIES': {'p': 0.14986376021798364, 'r': 0.2511415525114155, 'f': 0.18771331058020477}, 'DISEASE': {'p': 0.26103421258814313, 'r': 0.39717862110073515, 'f': 0.31502639665904975}}, 'speed': 8751.493417262382}\n",
      "1     | 115415.92 | 056.26 | 061.39 | 058.71 | S        | 02:18:17\n",
      "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.5626001811972959, 'ents_r': 0.6139323535562865, 'ents_f': 0.5871464547743948, 'ents_per_type': {'DRUG-PROTEIN': {'p': 0.45229796023754193, 'r': 0.6021828807150224, 'f': 0.5165880271306399}, 'CHEMICAL': {'p': 0.6255657272166221, 'r': 0.698389458272328, 'f': 0.6599747697399655}, 'SPECIES': {'p': 0.19458668617410388, 'r': 0.24292237442922374, 'f': 0.21608448415922016}, 'DISEASE': {'p': 0.41904184354154034, 'r': 0.13729386052056428, 'f': 0.20682430410056868}}, 'speed': 8607.040519668499}\n",
      "2     | 112997.56 | 053.63 | 059.37 | 056.36 | N        | 02:18:30\n",
      "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.5363147680629261, 'ents_r': 0.5937220754035402, 'ents_f': 0.5635602396592796, 'ents_per_type': {'DRUG-PROTEIN': {'p': 0.3698434577138919, 'r': 0.6456686146442077, 'f': 0.47029733959311426}, 'CHEMICAL': {'p': 0.6553792292019399, 'r': 0.6556426377285907, 'f': 0.6555109070034443}, 'SPECIES': {'p': 0.1702017589239524, 'r': 0.3004566210045662, 'f': 0.21730515191545574}, 'DISEASE': {'p': 0.4836716681376876, 'r': 0.10888138287303795, 'f': 0.17774894583198184}}, 'speed': 8401.558639342587}\n",
      "3     | 111511.72 | 051.29 | 067.79 | 058.39 | N        | 02:16:27\n",
      "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.5128817411568394, 'ents_r': 0.6778713614844953, 'ents_f': 0.583946148680741, 'ents_per_type': {'DRUG-PROTEIN': {'p': 0.40593641068976444, 'r': 0.6605362667583362, 'f': 0.5028459273797842}, 'CHEMICAL': {'p': 0.5705657772696879, 'r': 0.7593948267447536, 'f': 0.6515752395497205}, 'SPECIES': {'p': 0.1901743264659271, 'r': 0.1095890410958904, 'f': 0.13904982618771725}, 'DISEASE': {'p': 0.3887496519075466, 'r': 0.2773693622094178, 'f': 0.323747680890538}}, 'speed': 8655.87972335365}\n",
      "4     | 111101.78 | 054.52 | 060.24 | 057.24 | N        | 02:15:47\n",
      "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.5451823812801101, 'ents_r': 0.6024297963762192, 'ents_f': 0.572378225566083, 'ents_per_type': {'DRUG-PROTEIN': {'p': 0.37544544788869905, 'r': 0.6609659676864902, 'f': 0.47887674729927465}, 'CHEMICAL': {'p': 0.6940404559610558, 'r': 0.6589728131369679, 'f': 0.6760521897917711}, 'SPECIES': {'p': 0.1225986727209221, 'r': 0.32054794520547947, 'f': 0.1773623041940374}, 'DISEASE': {'p': 0.40612124779281933, 'r': 0.13709517186568648, 'f': 0.20499108734402852}}, 'speed': 8654.92448894478}\n",
      "5     | 109720.62 | 062.00 | 053.03 | 057.17 | N        | 02:15:37\n",
      "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'ents_p': 0.6200288985217295, 'ents_r': 0.5302964047379128, 'ents_f': 0.5716628066651637, 'ents_per_type': {'DRUG-PROTEIN': {'p': 0.4441617908929026, 'r': 0.600206256445514, 'f': 0.5105263157894737}, 'CHEMICAL': {'p': 0.7359886305662853, 'r': 0.5798237303706255, 'f': 0.6486391007627459}, 'SPECIES': {'p': 0.17473684210526316, 'r': 0.07579908675799087, 'f': 0.10573248407643311}, 'DISEASE': {'p': 0.46726190476190477, 'r': 0.12477647526326247, 'f': 0.19695781715540225}}, 'speed': 8590.370989701632}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-c84a61f8e473>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLABEL_SPECIES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTRAIN_DATASET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_by_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvalidate_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLABEL_SPECIES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVALIDATE_DATASET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup_by_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mnlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_spacy_multiple_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidate_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mlista_model_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Treino Agregado sem Word Vector\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-d15403a16e75>\u001b[0m in \u001b[0;36mtrain_spacy_multiple_label\u001b[1;34m(train_data, validate_data, iterations, lista_model_label, description)\u001b[0m\n\u001b[0;32m     33\u001b[0m                         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                         \u001b[0mexample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mannotations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                         nlp_train.update( [example],\n\u001b[0m\u001b[0;32m     36\u001b[0m                             \u001b[0mdrop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                             \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp-gpu\\lib\\site-packages\\spacy\\language.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude)\u001b[0m\n\u001b[0;32m   1105\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mexclude\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"update\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1107\u001b[1;33m             \u001b[0mproc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcomponent_cfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1108\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msgd\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp-gpu\\lib\\site-packages\\spacy\\pipeline\\transition_parser.pyx\u001b[0m in \u001b[0;36mspacy.pipeline.transition_parser.Parser.update\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp-gpu\\lib\\site-packages\\spacy\\ml\\parser_model.pyx\u001b[0m in \u001b[0;36mspacy.ml.parser_model.ParserStepModel.finish_steps\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp-gpu\\lib\\site-packages\\spacy\\ml\\parser_model.pyx\u001b[0m in \u001b[0;36mspacy.ml.parser_model.precompute_hiddens.begin_update.backward\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp-gpu\\lib\\site-packages\\spacy\\ml\\_precomputable_affine.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(dY_ids)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mdY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnP\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;31m# nB = dY.shape[0]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minc_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pad\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_backprop_precomputable_affine_padding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m         \u001b[0mXf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mids\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mXf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnF\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnI\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\nlp-gpu\\lib\\site-packages\\spacy\\ml\\_precomputable_affine.py\u001b[0m in \u001b[0;36m_backprop_precomputable_affine_padding\u001b[1;34m(model, dY, ids)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# (ids < 0).T @ dY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mids\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"f\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0md_pad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnO\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0md_pad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnO\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data =  load_data(LABEL_SPECIES, TRAIN_DATASET, group_by_label=False)\n",
    "validate_data = load_data(LABEL_SPECIES, VALIDATE_DATASET, group_by_label=False)\n",
    "nlp = train_spacy_multiple_label(train_data,validate_data, 10,  lista_model_label, \"Treino Agregado sem Word Vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-restaurant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
